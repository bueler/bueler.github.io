\documentclass[11pt]{article}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.75in} 
\addtolength{\evensidemargin}{-.75in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.3in}

\renewcommand{\baselinestretch}{1.075}

\usepackage{verbatim,fancyvrb}

\usepackage{palatino,amsmath,amssymb,amsthm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}

\newtheorem*{thm}{Theorem}
\newtheorem*{defn}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\newtheorem*{remark}{Remark}

\newcommand{\mtt}{\texttt}
\usepackage{alltt,xspace}

%\usepackage[final]{graphicx}

\usepackage[pdftex, colorlinks=true, plainpages=false, linkcolor=blue, citecolor=red, urlcolor=blue]{hyperref}

% macros
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}

\renewcommand{\Re}{\operatorname{Re}}
\renewcommand{\Im}{\operatorname{Im}}
\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}

%\renewcommand{\det}{\operatorname{det}}
\newcommand{\onull}{\operatorname{null}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\range}{\operatorname{range}}
\newcommand{\image}{\operatorname{im}}

\newcommand{\prob}[1]{\bigskip\noindent\textbf{#1.}\quad }
\newcommand{\exer}[2]{\prob{Exercise #2 in Lecture #1}}

\newcommand{\pts}[1]{(\emph{#1 pts}) }
\newcommand{\epart}[1]{\medskip\noindent\textbf{(#1)}\quad }
\newcommand{\ppart}[1]{\,\textbf{(#1)}\quad }

\newcommand{\Julia}{\textsc{Julia}\xspace}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\Python}{\textsc{Python}\xspace}

\DefineVerbatimEnvironment{mVerb}{Verbatim}{numbersep=2mm,
frame=lines,framerule=0.1mm,framesep=2mm,xleftmargin=4mm,fontsize=\footnotesize}

\newcommand{\ema}{\emach}
\newcommand{\emach}{\eps_{\!_{\text{m}}}}

\title{A Hilbert Space Alphabet \\ (or \emph{the correct sequence in which to introduce Hilbert spaces})}
\author{Ed Bueler\footnote{\today}}
%\date{\today}
\date{}

\begin{document}
\maketitle

I have already made video lectures for this material, and this is \emph{not} a revision!  You do not have to read it, but it might be useful for review or clarification.

Looking back, I did not do things in the correct sequence.  This short document shows a better sequence in which to introduce Hilbert spaces, up to the point where we start discussing operators on such spaces.  It is superior to how our textbook by Muscat\footnote{J.~Muscat, \emph{Functional Analysis: An Introduction to Metric Spaces, Hilbert Spaces, and Banach Algebras}, Springer, 2014} did it.  (How Muscat names things, e.g.~confusing Bessel's inequality and Parseval's identity, irritates me.)  It is certainly more efficient than the way I did it in the video lectures.  The sequence here is close to the way the material is presented by Reed \& Simon,\footnote{M.~Reed and B.~Simon, \emph{Functional Analysis}, Methods of Modern Math.~Phys.~I, Academic Press 1980} an excellent textbook.

Often the proof or presentation given by Muscat is just fine, so I just cite it.  Regarding which material is more efficient here, see \textbf{D}--\textbf{G} and FIXME: ON basis material

\vspace{0.25in}

\begin{enumerate}
\renewcommand{\labelenumi}{{\Large \textbf{\Alph{enumi}.}}\,}
\item Define a $\CC$-\emph{inner product space} $(X,\ip{\cdot}{\cdot})$.  The inner product is a sequilinear and positive-definite form.  See Muscat page 171.

\item Define the norm symbols $\|x\|=\sqrt{\ip{x}{x}}$.  However, this is not a norm because we have not proven triangle inequality (yet).

\item Define \emph{orthogonal vectors}: $\ip{u}{v}=0$.  Define \emph{orthonormal (ON) set}: $\{e_i\}_{i\in I}$ such that $\ip{e_i}{e_j}=0$ if $i\ne j$ and $\|e_i\|=1$.  Note that the index set $I$ in this definition can be any set, even uncountable.

\item \emph{Pythagorean Theorem.}  If $X$ is an inner product space and $u,v\in X$ are orthogonal then $\|u+v\|^2 = \|u\|^2 + \|v\|^2$.

\emph{proof.}  $\ip{u+v}{u+v} = \ip{u}{u} + 2 \Re\ip{u}{v} + \ip v v = \ip{u}{u} + \ip v v$.

\item \emph{Corollary (extended Pythagorean Theorem).}  If $X$ is an inner product space, $\{e_i\}_{i=1}^n$ is a finite ON set, and $x\in X$ then
    $$\|x\|^2 = \sum_{i=1}^n |\ip{e_i}{x}|^2 + \left\|x - \sum_{i=1}^n \ip{e_i}{x} e_i\right\|^2$$

\emph{proof.}  Let $u = \sum_{i=1}^n \ip{e_i}{x} e_i$ and $v = x - \sum_{i=1}^n \ip{e_i}{x} e_i$.  Clearly $x=u+v$.  Easy calculations show that $\ip{u}{v}=0$ and that $\|u\|^2 = \sum_{i=1}^n |\ip{e_i}{x}|^2$.  The result follows by the Pythagorean Theorem.

\item \emph{Corollary (Bessel's inequality).}  If $X$ is an inner product space and $\{e_i\}_{i=1}^n$ is a finite ON set and $x\in X$ then
    $$\|x\|^2 \ge \sum_{i=1}^n |\ip{e_i}{x}|^2$$

\emph{proof.}  Drop a term in the previous corollary.

\item \emph{Corollary (Cauchy-Schwarz).}  If $X$ is an inner product space and $x,y\in X$ then
    $$|\ip{x}{y}| \le \|x\|\|y\|.$$

\emph{proof.}  If $y=0$ the result is immediate.  Otherwise, $\{y/\|y\|\}$ is an ON set with one element.  Thus by Bessel's inequality, $\|x\|^2 \ge \left|\ip{\frac{y}{\|y\|}}{x}\right|^2 = \frac{|\ip{y}{x}|^2}{\|y\|^2}$.  The result follows by clearing denominators and taking square roots.

\item \emph{Corollary (Triangle inequality).}  If $X$ is an inner product space and $x,y\in X$ then
    $$\|x+y\| \le \|x\|+\|y\|.$$

\emph{proof.} By Cauchy-Schwarz,
   $$\|x+y\|^2 = \|x\|^2 + 2 \operatorname{Re}\ip{x}{y} + \|y\|^2 \le \|x\|^2 + 2 \|x\|\|y\| + \|y\|^2 = \left(\|x\|+\|y\|\right)^2.$$

\item \emph{Corollary.}  An inner product space is a normed vector space, thus a metric space.  The inner product is continuous.

\item \emph{Parallelogram law.}  If $X$ is an inner product space and $x,y\in X$ then
    $$\|x+y\|^2 + \|x-y\|^2 = 2 \|x\|^2 + 2 \|y\|^2$$

\emph{proof.} This is an easy computation: expand the left side and get the right side.

\emph{note.}  In fact, the parallelogram law characterizes inner product spaces among the normed vector spaces.  This was proven by P.~Jordan \& J. von Neumann (1935).  However, don't get distracted by that; keep going!

\item Define \emph{Hilbert space}:  A $\CC$-inner product space $(X,\ip{\cdot}{\cdot})$ is a \emph{Hilbert space} if it is complete as a normed vector space.

\item Define \emph{convex}:  Given a normed vector space $X$, a subset $A\subset X$ is \emph{convex} if $0\le \lambda \le 1$ and $u,v\in A$ imply $\lambda u + (1-\lambda) v\in A$.

\item \emph{Fundamental Theorem of Optimization.}  If $H$ is a Hilbert space,  $A \subset H$ is a closed and convex subset, and $x\in H$ then there is a unique $y_* \in A$ such that $\|x-y_*\| \le \|x-y\|$ for all $y\in A$.

\emph{proof.}  This is Theorem 10.11 in Muscat.  The proof uses the parallelogram law, the completeness of $H$, the closedness of $A$, and the convexity of $A$.

\emph{note.}  I assert this is a good name for the theorem, but it is not universal.

\item Define \emph{$A$-perp}:  If $X$ is an inner product space and $A\subset X$ is any subset then
    $$A^\perp = \left\{x\in X \,:\, \ip{x}{a}=0 \text{ for all } a \in A\right\}.$$

\item \emph{Lemma.} If $X$ is an inner product space and $A\subset X$ is any subset then $A^\perp$ is a closed linear subspace of $X$ and $A^\perp = \overline{(\operatorname{span} A)}^\perp$.

\emph{proof.} This is Proposition 10.9 in Muscat.  The proof uses the continuity of the inner product.

\item \emph{Theorem (orthogonal decomposition and projection).}  If $H$ is a Hilbert space, $M\subset H$ is a closed linear subspace, $x\in H$, and $y\in M$ then
    $$\left(y \text{ is the closest point in $M$ to } x\right) \iff x-y \in M^\perp.$$
Furthermore, $H=M\oplus M^\perp$.  Finally, $P:x\mapsto y$, where $y$ is the closest point in $M$ to $x$, defines $P\in B(H)$, an orthogonal projection onto $M$.

\emph{proof.}  This is Theorem 10.12 in Muscat.  The proof uses the Pythagorean theorem.  The fundamental theorem of optimization (and the completeness of $H$ and closedness of $M$) is needed so that a closest point exists.

\emph{note.}  The definition of ``orthogonal projection onto $M$'' is that $M=\image P$, $P^2=P$, and for all $x\in H$ we have $x-Px \perp M$.  Later we can simplify the last condition to $P^*=P$.

\item \emph{Lemma.}  If $X$ is an inner product space, $X^*$ is the dual space of continuous linear functionals, and $x\in X$ then $\phi(y) = \ip{x}{y}$ defines $\phi\in X^*$, and furthermore $\|\phi\| = \|x\|$.

\emph{proof.} By Cauchy-Schwarz, $|\phi(y)| = |\ip{x}{y}| \le \|x\|\|y\|$, thus $\phi$ is continuous and $\|\phi\|\le \|x\|$.  Also $\|\phi\|=\sup_{y\ne 0} \frac{|\ip{x}{y}|}{\|y\|} \ge \|x\|$ by choosing $y=x$.

\item Define the \emph{Riesz map}:  If $X$ is an inner product space then
\begin{align*}
J:X &\to X^* \\
  x &\mapsto \big[\,x^*: y\mapsto \ip{x}{y}\,\big]
\end{align*}

\item \emph{Riesz Representation Theorem}  If $H$ is a Hilbert space then the Riesz map $J:H \to H^*$ is bijective, conjugate-linear, and isometric.

\emph{proof.}  This is Theorem 10.16 in Muscat.  The proof uses the definition of $M^\perp$ for $M=\ker \phi$ and $\phi \in H^*$.  The continuity of $\phi$ shows $M$ is closed so $H=M\oplus M^\perp$ because $H$ is a Hilbert space (so we can use orthogonal decomposition).  Thus $J$ is onto.  The Lemma shows $J$ is isometric.  The remaining properties of $J$ follow from easy calculations.

\item Gram-Schmidt process.  any sequence of vectors in an inner product space $(X,\ip{\cdot}{\cdot})$ can be replaced by an ON set with same span

\item definition. $\{u_i\}_{i\in I} \subset X$, where $(X,\ip{\cdot}{\cdot})$ is an inner product space, is an \emph{ON basis} if it is ON set and the span (\underline{finite} linear combinations) is dense; note index set $I$ is arbitrary, possibly uncountable

\item Theorem. every Hilbert space has an ON basis

proof. page 202 Muscat; better situation than Banach spaces because not all Banach spaces have Schauder bases

\item Lemma.  if $\{e_i\}$ is a countable ON set in a Hilbert space $H$ then
    $$\left(\sum_i \alpha_i e_i \text{ converges in $H$ for $\alpha_i\in \CC$}\right) \iff (\alpha_i)\in \ell^2$$

proof. Prop 10.30 in Muscat; uses completeness of $H$ and $\ell^2$

\item Parseval's identity. if $\{e_i\}$ is a countable ON basis of a Hilbert space $H$, and if $x\in H$ then
    $$x = \sum_i \ip{e_i}{x}e_i, \qquad \|x\|^2 = \sum_i |\ip{e_i}{x}|^2$$

proof. uses Bessel's inequality and previous lemma

\item definition. given $T\in B(X,Y)$ define $T^*\in B(Y,X)$, the \emph{adjoint of $T$}, by $T^*y=w$ where $w$ represents functional $\phi(x) = \ip{y}{Tx}_X$, thus
    $$\ip{T^*y}{x} = \ip{y}{Tx}$$

\item FIXME: selection of other facts about adjoints

\end{enumerate}
\end{document}

