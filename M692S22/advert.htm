<!DOCTYPE html>
<html lang="en-US">

<head>
  <meta charset="utf-8">
  <meta name="author" content="Ed Bueler">
  <meta name="description" content="description/advertisement for Math 614 in Fall 2021 taught by Bueler">
  <title>ad for Math 692 Graduate Seminar in Mathematics of Machine Learning</title>
  <link href="../style.css" rel="stylesheet" type="text/css"/>
</head>

<body>
<h2>Math 692 Graduate Seminar</h2>

<h1>Mathematics of Machine Learning</h1>

<h2>Spring 2022, UAF</h2>

<table>
  <col style="width:45%;">
  <col style="width:55%;">
  <tr>
     <th>organizer</th>
     <th>details</th>
  </tr>
  <tr>
       <td><a href="https://bueler.github.io/">Ed Bueler</a>&nbsp;  (<a href="mailto:elbueler@alaska.edu">elbueler@alaska.edu</a>)</td>
       <td>time & room:&nbsp; Thurs. 3:45-4:45 Chapman <span style="text-decoration: line-through;">206</span> <span style="font-weight: bold;">106</span></td>
  </tr>
  <tr>
       <td></td>
       <td>maximum credits:&nbsp; 1.0</td>
  </tr>
</table>

<p>Multilayered artificial neural networks, and other styles of machine learning, are now pervasive in application fields.  At the heart of this deep learning revolution are familiar concepts from mathematics, starting with calculus, linear algebra, and optimization.</p>

<img src="figs/HH19-classification.png" style="float:left; padding: 10px 30px 15px 10px;" height="160" alt="classification visualization"> 

<p>This seminar is a participant-driven exploration of mathematical aspects of machine learning, including any related topics of interest, not limited to neural networks.  We will <em>start</em> from the basic ideas that underlie neural networks, from an applied mathematics perspective, and branch out from there.</p>

<p>We hope to include any interested students and faculty from across UAF.  The mathematics should at the introductory graduate or advanced undergraduate level, and any related, compelling application of mathematics is fair game!</p>

<p>Software libraries and statistical concepts are valuable topics for discussion and demonstration, and topics from statistics and computer science are welcome, but they might be covered elsewhere, e.g. in STAT 621 Nonparametric Statistics and CS 605 Artificial Intelligence graduate courses.</p>

<img src="figs/HH19-network.png" style="float:right" height="220" alt="a network with five layers">

<p>To get started, the organizer expects to give a talk based on the introductory review article by Higham & Higham (below):  <em>What is a deep neural network?  How is one trained?  What is the stochastic gradient method?  Back-propagation?  How is training related to least-squares problems?</em></p>

<p><b>Resources:</b>  One goal of the seminar will be to identify and collect some <em>open</em> resources, and there is a separate page already started for that purpose:

<h4 style="text-align: center;"><a href="resources.htm">mathy books/articles/blogs for machine learning</a></h4>
  
<p>For example, the seminar starting point will be this excellent survey article:</p>
<ul>
  <li>Higham, C. F., & Higham, D. J. (2019). <a href="http://www.math.stonybrook.edu/~bishop/classes/math533.S21/MachineLearning/SIAMreview.pdf"><em>Deep learning: An introduction for applied mathematicians.</em></a> SIAM Review, 61(4), 860-891.</li>
</ul>

<p><b>Credit:&nbsp;</b> Students who expect to earn 1.0 credits for this seminar should plan to give at least 2 (casual!) half-hour talks sometime during the semester.  Anyone can receive 0.0 credits under any conditions!</p>

<p><b>Prerequisites:&nbsp;</b> Graduate standing or permission of instructor.</p>

<img src="figs/HH19-cnnimage.png" style="display: block; margin-left: auto;
  margin-right: auto;" height="150" alt="convolutional neural network for image classification">

</body>
</html>
