\documentclass[11pt]{article}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.75in} 
\addtolength{\evensidemargin}{-.75in}
\addtolength{\topmargin}{-.4in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.0in}

\renewcommand{\baselinestretch}{1.075}

\usepackage{verbatim,fancyvrb}

\usepackage{palatino,amsmath,amssymb,amsthm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}

\newtheorem*{thm}{Theorem}
\newtheorem*{defn}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\newtheorem*{remark}{Remark}

\newcommand{\mtt}{\texttt}
\usepackage{alltt,xspace}
\newcommand{\mfile}[1]
{\medskip\begin{quote}\scriptsize \begin{alltt}\input{#1.m}\end{alltt} \normalsize\end{quote}\medskip}

%\usepackage[final]{graphicx}

\usepackage[pdftex, colorlinks=true, plainpages=false, linkcolor=blue, citecolor=red, urlcolor=blue]{hyperref}

% macros
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}

\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}

%\renewcommand{\det}{\operatorname{det}}
\newcommand{\onull}{\operatorname{null}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\range}{\operatorname{range}}

\newcommand{\prob}[1]{\bigskip\noindent\textbf{#1.}\quad }
\newcommand{\exer}[2]{\prob{Exercise #2 in Lecture #1}}

\newcommand{\pts}[1]{(\emph{#1 pts}) }
\newcommand{\epart}[1]{\medskip\noindent\textbf{(#1)}\quad }
\newcommand{\ppart}[1]{\,\textbf{(#1)}\quad }

\newcommand{\Julia}{\textsc{Julia}\xspace}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\Python}{\textsc{Python}\xspace}

\DefineVerbatimEnvironment{mVerb}{Verbatim}{numbersep=2mm,
frame=lines,framerule=0.1mm,framesep=2mm,xleftmargin=4mm,fontsize=\footnotesize}

\newcommand{\ema}{\emach}
\newcommand{\emach}{\eps_{\!_{\text{m}}}}

\title{POPDIP: \\ a POsitive-variables Primal-Dual Interior Point method}
\author{Ed Bueler}
\date{\today}

\begin{document}
\maketitle

%\abstract{This is not research, but it is a new algorithm for me.  It is a version of the primal dual interior point algorithm in \cite{GrivaNashSofer2009}.}
\begin{abstract}
The algorithm documented here is a version of the primal dual interior point algorithm in \cite{GrivaNashSofer2009}; see section 16.7 and Algorithm 16.1.  The version here minimizes a smooth nonlinear function subject to the specialized constraints that all the variables are nonnegative.

These short notes are not research!  This algorithm is simply a special case of a well-known algorithm, and furthermore ``POPDIP'' is just a name I made up; it is not in common use!  However, it is new to me so I am documenting it fully.
\end{abstract}

\thispagestyle{empty}

\bigskip
Consider a nonlinear optimization problem with positivity constraints on the variables:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{minproblem}
\end{equation}
Here $f:\RR^n\to\RR^n$ is a smooth function and ``$x\ge 0$'' means that each entry of $x\in\RR^n$ is nonnegative.  The feasible set for \eqref{minproblem} is the convex and closed set $S = \{x\in \RR^n\,:\,x\ge 0\}$ with interior $S^\circ = \{x\in \RR^n\,:\,x > 0\}$.

One can start the derivation by considering a logarithmic barrier function.  Let $\mu>0$.  If $x\in S^\circ$ then the following function is well-defined and finite:
\begin{equation}
\beta_\mu = f(x) - \mu \sum_{i=1}^n \ln x_i \label{barrierfunction}
\end{equation}
The first-order necessary conditions for the unconstrained problem of minimizing $\beta_\mu$, namely $\grad \beta_\mu(x)=0$ for $x \in S^\circ$, are
\begin{align}
x &> 0 \label{firstorderbarrier} \\
\grad f(x) - \mu \sum_{i=1}^n \frac{1}{x_i} e_i &= 0 \notag
\end{align}
Here $\{e_1,\dots,e_n\}$ is the standard basis of $\RR^n$.

Conditions \eqref{firstorderbarrier} can be reformulated by defining additional variables
    $$\lambda_i = \frac{\mu}{x_i}$$
where $\lambda\in\RR^n$.  Note that $\lambda>0$ if and only if $x>0$ because $\lambda_i x_i = \mu > 0$.  Then \eqref{firstorderbarrier} is precisely equivalent to the following nonlinear system of equations and inequalities:
\begin{align}
x &\ge 0 \label{firstordersystem} \\
\lambda &\ge 0 \notag \\
\grad f(x) - \sum_{i=1}^n \lambda_i e_i &= 0 \notag \\
\lambda_i x_i &= \mu, \qquad i=1,\dots,n \notag
\end{align}

Because of the last condition in \eqref{firstordersystem}, both $x$ and $\lambda$ are positive and thus in the interiors of their respective feasible sets.  For the general primal-dual interior point algorithm, specifically Algorithm 16.1 in section 16.7 of \cite{GrivaNashSofer2009}, the feasible set for the primal variable $x$ is different from the feasible set for the dual variable $\lambda$.  For example, generally the dimension is different.  However, in our case the feasible set is $S$ for each variable separately.

The third condition in \eqref{firstordersystem} is related to a Lagrangian function for \eqref{minproblem}, namely
    $$\mathcal{L}(x,\lambda) = f(x) - \sum_{i=1}^n \lambda_i x_i.$$
The third condition is the statement that $\grad_x \mathcal{L}(x,\lambda)=0$.  However, the whole system \eqref{firstordersystem} describes a solution which is generally different from an unconstrained stationary point of the Lagrangian.  There is an additional connection between the variables ($\lambda_i x_i = \mu$) and there are additional nonnegativity constraints ($x\ge 0$ and $\lambda\ge 0$) so generally ``$\grad_x\mathcal{L}(x,\lambda)=0$ and $\grad_\lambda\mathcal{L}(x,\lambda)=0$'' does not hold at the solution.

Algorithm 16.1 in \cite{GrivaNashSofer2009} applies to \eqref{minproblem}, and the POPDIP algorithm proposed below is the simplification which uses the fact that $g_i(x)=x_i$.  These algorithms compute approximate solutions to \eqref{firstordersystem} for a sequence $\mu=\mu^{(k)} \to 0$.  In that limit the exact solution solves \eqref{firstordersystem} with $\mu$ replaced by zero.  These are the KKT conditions for \eqref{minproblem}---see Lemma 14.8 and Theorem 14.18 in \cite{GrivaNashSofer2009}---including the complementarity statement $\lambda_i x_i=0$.

Each step of the algorithm is a Newton step for the nonlinear system of equalities from \eqref{firstordersystem},
\begin{align}
\grad f(x) - \sum_{i=1}^n \lambda_i e_i &= 0 \label{equalitysystem} \\
\lambda_i x_i &= \mu, \qquad i=1,\dots,n. \notag
\end{align}
The Newton method updates both $x$ and $\lambda$ using the linearization of these equations.  To describe the Newton step let $x=x^{(k)}+\Delta x$, $\lambda=\lambda^{(k)}+\Delta\lambda$, and $\mu=\mu^{(k)}$.  Note that the current iterate, namely $(x^{(k)},\lambda^{(k)})$, generally does not solve \eqref{equalitysystem}.  The unknowns in the Newton step are the search direction $p=(\Delta x,\Delta \lambda)$.  Substituting into \eqref{equalitysystem} and expanding to first order gives
\begin{align}
\grad f(x^{(k)}) - \sum_{i=1}^n \lambda_i^{(k)} e_i + \grad^2 f(x^{(k)}) \Delta x - \sum_{i=1}^n (\Delta \lambda)_i e_i &= 0 \label{prenewtonstep} \\
\lambda_i^{(k)} x_i^{(k)} + x_i^{(k)} (\Delta\lambda)_i + \lambda_i^{(k)} (\Delta x)_i &= \mu^{(k)}, \qquad i=1,\dots,n \notag
\end{align}
Rearranging as a linear block system for the search direction, and suppressing the superscript on the current iterate gives the Newton step equations
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
\Lambda & X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \sum_{i=1}^n \lambda_i e_i \\
-\Lambda x + \mu^{(k)} e
\end{bmatrix}
 \label{newtonstep}
\end{equation}
where $I$ is the $n\times n$ identity matrix and the other notation is as follows:
    $$\Lambda = \begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix}, \qquad X = \begin{bmatrix} x_1 & & \\ & \ddots & \\ & & x_n \end{bmatrix}, \qquad e = \begin{bmatrix} 1 \\ \vdots \\ 1 \end{bmatrix}.$$

Equation \eqref{newtonstep} can be symmetrized by multiplying the second half of the equations by $-\Lambda^{-1}$:
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
-I & - \Lambda^{-1} X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \sum_{i=1}^n \lambda_i e_i \\
x - \mu^{(k)} \Lambda^{-1} e
\end{bmatrix}
 \label{symmnewtonstep}
\end{equation}
However, it is not clear to me whether solving \eqref{newtonstep} or \eqref{symmnewtonstep} leads to a better algorithm.

In Algorithm 16.1 the computation of the Newton search direction is followed by separate line searches in $x$ and in $\lambda$.  The goals of these line searches is only to maintain the nonnegativity requirements ($g_i(x)\ge 0$ and $\lambda_i\ge 0$, in general) and not to get sufficient decrease of $f(x)$.  Even for the general case the line search on $\lambda$ is merely the application of the ratio test.  These facts suggests two possible areas for improvement of the algorithm:
\begin{enumerate}
\item Because of the linearity of the constraint functions in problem \eqref{minproblem}, namely $g_i(x)=x_i$, a ratio test on $x$ also suffices to keep $x$ feasible.
\item Back-tracking line search is appropriate as a globalization even for unconstrained optimization.  Thus there are cases where it is appropriate for problem \eqref{minproblem} as well.
\end{enumerate}
For now we will implement improvement 1 but keep 2 in reserve as a possible further improvement.

The optimality test in Algorithm 16.1 uses the merit function
    $$\nu(x,\lambda) = $$

\bigskip
\noindent \textsc{Algorithm. the POsitive-variables Primal-Dual Interior Point method.}
\begin{quote}
\begin{itemize}
\item[\emph{input}]  FIXME
\item[\emph{output}]  FIXME
\end{itemize}
\renewcommand{\labelenumi}{\arabic{enumi}.}
\begin{enumerate}
\item FIXME
\item For $k=0,1,2,\dots$
    \renewcommand{\labelenumii}{(\alph{enumii})}
    \begin{enumerate}
    \item FIXME
    \end{enumerate}
\end{enumerate}
\end{quote}


\bibliography{popdip}
\bibliographystyle{siam}

\end{document}

