\documentclass[11pt]{article}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.75in} 
\addtolength{\evensidemargin}{-.75in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.3in}

\renewcommand{\baselinestretch}{1.075}

\usepackage{verbatim,fancyvrb}

\usepackage{palatino,amsmath,amssymb,amsthm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}

\newtheorem*{thm}{Theorem}
\newtheorem*{defn}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\newtheorem*{remark}{Remark}

\newcommand{\mtt}{\texttt}
\usepackage{alltt,xspace}

%\usepackage[final]{graphicx}

\usepackage[pdftex, colorlinks=true, plainpages=false, linkcolor=blue, citecolor=red, urlcolor=blue]{hyperref}

% macros
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}

\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}

%\renewcommand{\det}{\operatorname{det}}
\newcommand{\onull}{\operatorname{null}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\range}{\operatorname{range}}

\newcommand{\prob}[1]{\bigskip\noindent\textbf{#1.}\quad }
\newcommand{\exer}[2]{\prob{Exercise #2 in Lecture #1}}

\newcommand{\pts}[1]{(\emph{#1 pts}) }
\newcommand{\epart}[1]{\medskip\noindent\textbf{(#1)}\quad }
\newcommand{\ppart}[1]{\,\textbf{(#1)}\quad }

\newcommand{\Julia}{\textsc{Julia}\xspace}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\Python}{\textsc{Python}\xspace}

\DefineVerbatimEnvironment{mVerb}{Verbatim}{numbersep=2mm,
frame=lines,framerule=0.1mm,framesep=2mm,xleftmargin=4mm,fontsize=\footnotesize}

\newcommand{\ema}{\emach}
\newcommand{\emach}{\eps_{\!_{\text{m}}}}

\title{POPDIP: \\ a POsitive-variables Primal-Dual Interior Point method}
\author{Ed Bueler}
\date{\today}

\begin{document}
\maketitle

\begin{abstract}
The algorithm documented here is a version of a Newton-type primal-dual interior point algorithm in \cite{GrivaNashSofer2009}, namely Algorithm 16.1 in section 16.7.  The version here minimizes a smooth nonlinear function subject to the simple constraints that all the variables are nonnegative.  That is, it is a specialized algorithm for nonnegativity constraints; it is not suitable for general inequality constraints.

These short notes are not research as this algorithm is simply a special case of a well-known algorithm.  Furthermore ``POPDIP'' is just a name I made up; it is not in common use!  However, this class of algorithms is new to me so I am documenting it fully.
\end{abstract}

\thispagestyle{empty}

\bigskip
\subsection*{Introduction}

Consider a nonlinear optimization problem with nonnegativity (informally: positivity) constraints on the variables:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{minproblem}
\end{equation}
As usual, ``$x\ge 0$'' means that each entry of $x\in\RR^n$ is nonnegative.  The feasible set for \eqref{minproblem} is the convex and closed set $S = \{x\in \RR^n\,:\,x\ge 0\}$ with interior $S^\circ = \{x\in \RR^n\,:\,x > 0\}$.

Here $f:\RR^n \to\RR^n$ is a continuous and smooth function.  In fact this algorithm only assumes $f$ is defined and smooth on $S^\circ$, but in practice, so as to have a chance of good performance, $f$ should be well-behaved near the boundary of $S$.

One can start the derivation by considering a logarithmic barrier function.  Let $\mu>0$.  If $x\in S^\circ$ then the following function is well-defined and finite:
\begin{equation}
\beta_\mu(x) = f(x) - \mu \sum_{i=1}^n \ln x_i \label{barrierfunction}
\end{equation}
Let $\{e_1,\dots,e_n\}$ be the standard basis of $\RR^n$.  The first-order necessary condition for the unconstrained problem of minimizing $\beta_\mu$, namely $\grad \beta_\mu(x)=0$ for $x \in S^\circ$, is
\begin{equation}
\grad f(x) - \mu \sum_{i=1}^n \frac{1}{x_i} e_i = 0 \label{firstorderbarrier}
\end{equation}

Conditions \eqref{firstorderbarrier} can be reformulated by defining additional variables
    $$\lambda_i = \frac{\mu}{x_i}$$
so that $\lambda\in\RR^n$.  Note that $\lambda>0$ if and only if $x>0$ because $\lambda_i x_i = \mu > 0$.  Then \eqref{firstorderbarrier}, plus feasibility for $x$, is precisely equivalent to the following nonlinear system of equations and inequalities:
\begin{align}
x &\ge 0 \label{firstordersystem} \\
\lambda &\ge 0 \notag \\
\grad f(x) - \lambda &= 0 \notag \\
\lambda_i x_i &= \mu, \qquad i=1,\dots,n \notag
\end{align}

The feasible set for $x$ and for $\lambda$ is the same, namely $S \subset \RR^n$.  Because of the last condition in \eqref{firstordersystem}, both $x$ and $\lambda$ are positive and thus in the interior $S^\circ$.  By contrast, for the general primal-dual interior point Algorithm 16.1 \cite[section 16.7]{GrivaNashSofer2009}, the feasible set for the primal variable $x$ is different from the dual feasible set for $\lambda$.  For example, generally the dimension is different.

The third condition in \eqref{firstordersystem} can be written using a Lagrangian function for \eqref{minproblem}, namely
\begin{equation}
\mathcal{L}(x,\lambda) = f(x) - \sum_{i=1}^n \lambda_i x_i,  \label{Lagrangian}
\end{equation}
in which case the third condition states that $\grad_x \mathcal{L}(x,\lambda)=0$.  In fact, the KKT conditions \cite[sections 14.4, 14.5]{GrivaNashSofer2009} are nearly the same as \eqref{firstordersystem} but with the last equation replaced by a condition of complementary slackness,
\begin{align}
x &\ge 0 \label{KKT} \\
\lambda &\ge 0 \notag \\
\grad f(x) - \lambda &= 0 \notag \\
\lambda_i x_i &= 0, \qquad i=1,\dots,n \notag
\end{align}
System \eqref{firstordersystem} modifies these KKT conditions by changing complementary slackness to a connection between the primal and dual variables.  Their product is set to a positive constant.  Thus system \eqref{firstordersystem} describes a solution which is different from the KKT conditions for \eqref{minproblem}.

The stationary-point conditions for Lagrangian \eqref{Lagrangian} which would apply in the absence of positivity constraints, namely $\grad_x\mathcal{L}(x,\lambda)=0$ and $\grad_\lambda\mathcal{L}(x,\lambda)=0$, do not generally apply, of course.  (Making the inequality constraints into equalities would make the problem trivial!)  However, $x_i=0$ holds by definition when the $i$th constraint is active.  The algorithm here will not keep track of the active set but rather allow determination of the active set upon convergence, by use of a near-zero tolerance.

One of the KKT conditions \eqref{KKT} is $\grad f(x)-\lambda=0$ so $\lambda$ can be easily eliminated if desired.  In fact, writing the conditions without the dual variables gives a \emph{nonlinear complementary problem} (NCP) \cite{FacchineiPang2007},
    $$x \ge 0, \qquad F(x) \ge 0, \qquad x_i F(x)_i = 0$$
where $F(x) = \grad f(x)$ is a vector-valued function.  Thus we can regard our method as solving the barrier-modified NCP
    $$x \ge 0, \qquad F(x) \ge 0, \qquad x_i F(x)_i = \mu.$$
However, a primal-dual method for this NCP would re-introduce the dual variables so there is no benefit here of an NCP formulation other than to note the connection for future reference.  (An NCP formulation is appropriate if the problem were a variational inequality \cite{BensonMunson2006,Bueler2016} instead of actual optimization.)


\subsection*{Algorithm design}

Algorithm 16.1 \cite{GrivaNashSofer2009} applies to \eqref{minproblem}.  The POPDIP algorithm proposed below is the simplification for $g_i(x)=x_i$.  All such primal-dual interior point algorithms \cite{NocedalWright2006} compute approximate solutions to systems like \eqref{firstordersystem} for a sequence $\{\mu_k>0\}$ going to zero.  The limit where $\mu=0$, never achieved because the algorithm is terminated after a finite number of steps, solves the KKT conditions \eqref{KKT}.

Each step of the algorithm is a Newton step for the equalities in \eqref{firstordersystem}, namely
\begin{align}
\grad f(x) - \lambda &= 0 \label{equalitysystem} \\
\lambda_i x_i &= \mu_k, \qquad i=1,\dots,n. \notag
\end{align}
The step updates both $x$ and $\lambda$ using the linearization of these equations.

Because of the second equation, \eqref{equalitysystem} is always a nonlinear system.  However, if $f$ is quadratic then the first equation is linear.

To describe the Newton step let $x=x_k+\Delta x$ and $\lambda=\lambda_k+\Delta\lambda$.  We assume that the current iterate $(x_k,\lambda_k)$ does not solve \eqref{equalitysystem}.  The unknowns in the Newton step form the search direction $p=(\Delta x,\Delta \lambda)$.  Substituting into \eqref{equalitysystem} and expanding to first order gives
\begin{align}
\grad f(x_k) + \grad^2 f(x_k) \Delta x - \lambda_k - \Delta \lambda &= 0 \label{prenewtonstep} \\
(\lambda_k)_i (x_k)_i + (x_k)_i (\Delta\lambda)_i + (\lambda_k)_i (\Delta x)_i &= \mu_k, \qquad i=1,\dots,n \notag
\end{align}
Rearranging as a linear block system for the search direction, and suppressing the current-iterate subscript, we get step equations
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
\Lambda & X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
-\Lambda x + \mu_k e
\end{bmatrix}
 \label{newtonstep}
\end{equation}
Here $I$ is the $n\times n$ identity matrix and the other notation is as follows:
    $$\Lambda = \begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix}, \qquad X = \begin{bmatrix} x_1 & & \\ & \ddots & \\ & & x_n \end{bmatrix}, \qquad e = \begin{bmatrix} 1 \\ \vdots \\ 1 \end{bmatrix}.$$

Given a solution of \eqref{newtonstep} the update formulas are
\begin{align*}
x_{k+1} &= x_k + \alpha \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha \Delta \lambda
\end{align*}
A single maximum step size $\alpha$ for both the primal and dual variables is determined by a condition of (strict) positivity for both $x_{k+1}$ and $\lambda_{k+1}$ \cite{NocedalWright2006}.  (A ratio test suffices to keep $x$ feasible, in common with how the slack variables are limited in a general primal-dual interior point method \cite[subsection 16.7.2]{GrivaNashSofer2009}.  Back-tracking is not needed to maintain feasibility of the primal variables because of the linearity of the constraint functions in \eqref{minproblem}, namely $g_i(x)=x_i$.)  Because this is a Newton search one uses $\alpha=1$ for the largest allowed step.  Note we use $p=(\Delta x,\Delta \lambda) \in \RR^{2n}$ as a search direction.

The optimality test is the same as in Algorithm 16.1 \cite{GrivaNashSofer2009}.  It uses the merit function
\begin{equation}
    \nu(x,\lambda) = \max\{\|\grad f(x)-\lambda\|,\|\Lambda x\|\}  \label{merit}
\end{equation}
where $\|\cdot\|$ denotes the usual $L^2$ norm on $\RR^n$.  Note that once $\mu_k\to 0$ we have $\nu(x_*,\lambda_*) = 0$ for the exact optimum, but when $\mu_k \ne 0$ then the exact solution of \eqref{equalitysystem} does not make $\nu(x,\lambda)$ zero.  In fact $\nu(x_*,\lambda_*) = \sqrt{n}\, \mu_k$ for the exact solution of \eqref{equalitysystem}; if the merit function value $\nu(x_k,\lambda_k)$ is close to $\sqrt{n}\, \mu_k$ then we should decrease $\mu_k$ more rapidly.

Subsection 16.7.2 of \cite{GrivaNashSofer2009} describes how Algorithm 16.1 should be modified so that, by Theorem 16.17, the algorithm will exhibit the local quadratic convergence.\footnote{One would want this property for a Newton-type algorithm, but quadratic convergence is much harder to achieve in a constrained problem.  Thus I am interested in this algorithm!}  They describe how the general inequality constraints should be augmented by slack (excess) variables which have simple nonnegativity constraints, but in our case the constraints are already of that type.\footnote{The general replacement ``$g_i(x)\ge 0$'' by ``$g_i(x) - s_i =0$, $s_i\ge 0$'' would be, in our case, the replacement ``$x_i\ge 0$'' by ``$x_i-s_i=0$, $s_i\ge 0$.''  Clearly this is a meaningless renaming of the existing variables.}  However, Theorem 16.17 also uses a specific barrier parameter update for $\mu_k$ and a specific parameter choice for $\kappa$ in the ratio test.  In our case these are equations
\begin{align*}
\mu_k &= \min\{\theta \nu(x_k,\lambda_k),\nu(x_k,\lambda_k)^2\}, \\
\kappa &= \max\{\bar\kappa,1-\nu(x_k,\lambda_k)\},
\end{align*}
for parameters $0<\theta<1$ and $0<\bar\kappa<1$.  We choose these parameters based on the minimal hints in Example 16.16 on pages 643--644.

The method by which the initial dual variables are determined (below) is a somewhat ad hoc construction for which I have no reference.  This issue of initialization is discussed in \cite{Gertzetal2004}.


\subsection*{Algorithm}

We can now present a pseudocode for our algorithm.

\bigskip
\noindent \textsc{Algorithm POPDIP.}
\begin{quote}
\begin{itemize}
\item[\emph{inputs}]  primal initial values $x_0$ such that $x_0 > 0$
\item[]  smooth function $f$ returning $f(x)$, $\grad f(x)$, and $\grad^2 f(x)$
\item[\emph{parameters}]  $0<\text{\texttt{tol}}$ [default $\text{\texttt{tol}}=10^{-4}$]
\item[]  $\text{\texttt{maxiters}}>0$ [default $\text{\texttt{maxiters}}=200$]
\item[]  $0<\theta<1$ [default $\theta=0.1$]
\item[]  $0<\bar\kappa<1$ [default $\bar\kappa=0.9$]
\item[\emph{output}]  an estimate $(x_k,\lambda_k)$ of the solution
\item  determine initial dual variables:
    \renewcommand{\labelenumi}{(\roman{enumi})}
    \begin{enumerate}
    \item $y_0 = \grad f(x_0)$
    \item if $y_0 \le 0$ then $\mu_0=1$; otherwise $\mu_0$ is average of those products $(x_0)_i (y_0)i$ where $(y_0)_i > 0$
    \item $(\lambda_0)_i = \mu_0 / (x_0)_i$ for $i=1,\dots,n$
    \end{enumerate}
\item  for $k=0,1,2,\dots,\text{\texttt{maxiters}}-1$
    \renewcommand{\labelenumi}{(\roman{enumi})}
    \begin{enumerate}
    \item optimality test: if $\nu(x_k,\lambda_k)<\text{\texttt{tol}}$ then stop
    \item barrier parameter: $\mu_k = \min\{\theta \nu(x_k,\lambda_k),\nu(x_k,\lambda_k)^2\}$
    \item compute Newton step by solving this system for $(\Delta x,\Delta \lambda)$:
    $$\begin{bmatrix}
\grad^2 f(x_k) & - I \\
\Lambda_k & X_k
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x_k) + \lambda_k \\
-\Lambda_k x_k + \mu_k e
\end{bmatrix}$$
    \item ratio test for step sizes to keep $x_{k+1},\lambda_{k+1}$ positive:
\begin{align*}
\kappa &= \max\{\bar\kappa,1-\nu(x_k,\lambda_k)\} \\
\alpha &= \min_{1\le i\le n} \left\{1, \,-\kappa \frac{(x_k)_i}{(\Delta x)_i} \,:\, (\Delta x)_i < 0, \,-\kappa \frac{(\lambda_k)_i}{(\Delta \lambda)_i} \,:\, (\Delta \lambda)_i < 0\right\}
\end{align*}
    \item the update:
\begin{align*}
x_{k+1} &= x_k + \alpha \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha \Delta \lambda
\end{align*}
    \end{enumerate}
\end{itemize}
\end{quote}

This algorithm is implemented by a \Matlab code with signature

\medskip
\noindent \mbox{\texttt{function [xk,lamk,xklist,lamklist] = popdip(x0,f,tol,maxiters,theta,kappabar)}}

\medskip
\noindent Only inputs \texttt{x0,f} are required.  The parameters have the default values listed above.  If the outputs \texttt{xklist} and \texttt{lamklist} are not requested then they are not saved.

Download the code at
\begin{center}
    \href{http://bueler.github.io/M661F18/matlab/popdip.m}{\texttt{bueler.github.io/M661F18/matlab/popdip.m}}
\end{center}


\subsection*{Example 1}

We first try an easy 2D test problem in \href{http://bueler.github.io/M661F18/matlab/testpopdip.m}{\texttt{testpopdip.m}}:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) = \frac{1}{2} (x_1-1)^2 + \frac{1}{2} (x_2+1)^2 \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{testoneproblem}
\end{equation}
For this objective function $f$ the unconstrained minimum is the infeasible point $\hat x =(1,-1)^\top$.  A sketch shows that the exact solution of the constrained problem is $x_*=(1,0)^\top$.  Running the code with the given initial iterate $x_0=(2,2)^\top$ and \texttt{tol} $=10^{-14}$, and otherwise using the default parameters in POPDIP, gives
\begin{Verbatim}[fontsize=\small]
>> testpopdip([2 2]',1.0e-14)
  1:    2.000000000000000    2.000000000000000
  2:    1.641421356237309    0.641421356237310
  3:    1.245446520462486    0.245446520462486
  4:    1.069404818969903    0.069404818969903
  5:    1.013447008853577    0.013447008853577
  6:    1.000537794151783    0.000537794151783
  7:    1.000000867357066    0.000000867357066
  8:    1.000000000002257    0.000000000002257
  9:    1.000000000000000    0.000000000000000
\end{Verbatim}
The printed columns are $(x_k)_1$ and $(x_k)_2$.  Note the apparent quadratic, or at least strongly superlinear, convergence.  The iterates $x_k$ are graphed in the following figure.

\bigskip
\begin{center}
\includegraphics[width=0.6\textwidth]{testpopdip}
\end{center}


\subsection*{Example 2}

FIXME obstacle problem in 1D

\begin{equation}
    f[u] = \int_0^1 \frac{1}{2} |u'(x)|^2 - q(x) u(x)\,dx \label{obstaclefunctional}
\end{equation}

$\Delta x = 1 / (n+1)$
\begin{equation}
    f(u) = \Delta x \sum_{i=0}^n \left(\frac{1}{2} \left(\frac{u_{i+1}-u_i}{\Delta x}\right)^2 - q(x_{i+1/2}) \frac{u_i + u_{i+1}}{2}\right) \label{obstacleobjective}
\end{equation}
where $u_0=0$ and $u_{n+1}=0$ when they appear

gradient components for $i=1,\dots,n$
\begin{equation}
\grad f(u)_i = \frac{1}{\Delta x} \left\{\begin{matrix}
2 u_1 - u_2 & (i=1) \\
-u_{i-1} + 2 u_i - u_{i+1} & (1<i<n) \\
-u_{n-1} + 2 u_n & (i=n) \\
\end{matrix} \right\} - \frac{\Delta x}{2} (q(x_{i-1/2}) + q(x_{i+1/2}))
\end{equation}

Hessian matrix
\begin{equation}
\grad^2 f(u) = \frac{1}{\Delta x} \begin{bmatrix}
2  & -1 &    &    \\
-1 &  2 & -1 &    \\
   &    & \ddots &\\
   &    & -1 &  2
\end{bmatrix}
\end{equation}

\subsection*{Possible improvements}

We may consider possible improvements of our algorithm.  First, in Algorithm 16.1 the computation of the Newton search direction is followed by separate line searches in $x$ and in $\lambda$.  These line searches only maintain nonnegativity and they do not seek sufficient decrease of $f(x)$; they only use ratio tests.  Secondly, equation \eqref{newtonstep} can be symmetrized by multiplying the second half of the equations by $-\Lambda^{-1}$:
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
-I & - \Lambda^{-1} X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
x - \mu_k \Lambda^{-1} e
\end{bmatrix}
 \label{symmnewtonstep}
\end{equation}

FIXME further simplify into system of $n$ equations for $\lambda$ only

These facts suggests two possible changes:
\begin{enumerate}
\item Back-tracking line search is appropriate as a globalization even for unconstrained optimization.  Thus there must be cases where it is appropriate for problem \eqref{minproblem} as well.  Once the ratio tests are applied, further back-tracking could be used based on sufficient decrease.  Compare the modified back-tracking line searches in \cite{BensonMunson2006}.
\item One can replace linear system \eqref{newtonstep} with symmetrized system \eqref{symmnewtonstep}.
\end{enumerate}
Determining if these are actual improvements would require testing which we have not done.


%\subsection*{Application to example problem (\texttt{glacier}).}
%FIXME a primal-dual interior point method for a glacier problem appears in \cite{Calvoetal2003}

\medskip

\bibliography{doc}
\bibliographystyle{siam}

\end{document}

