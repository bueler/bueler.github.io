\documentclass[11pt]{article}
%prepared in AMSLaTeX, under LaTeX2e
\addtolength{\oddsidemargin}{-.75in} 
\addtolength{\evensidemargin}{-.75in}
\addtolength{\topmargin}{-.6in}
\addtolength{\textwidth}{1.4in}
\addtolength{\textheight}{1.3in}

\renewcommand{\baselinestretch}{1.075}

\usepackage{verbatim,fancyvrb}

\usepackage{palatino,amsmath,amssymb,amsthm}

\usepackage{tikz}
\usetikzlibrary{arrows.meta}

\newtheorem*{thm}{Theorem}
\newtheorem*{defn}{Definition}
\newtheorem*{example}{Example}
\newtheorem*{problem}{Problem}
\newtheorem*{remark}{Remark}

\newcommand{\mtt}{\texttt}
\usepackage{alltt,xspace}

%\usepackage[final]{graphicx}

\usepackage[pdftex, colorlinks=true, plainpages=false, linkcolor=blue, citecolor=red, urlcolor=blue]{hyperref}

% macros
\newcommand{\bc}{\mathbf{c}}
\newcommand{\br}{\mathbf{r}}
\newcommand{\bv}{\mathbf{v}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}

\newcommand{\CC}{\mathbb{C}}
\newcommand{\RR}{\mathbb{R}}
\newcommand{\ZZ}{\mathbb{Z}}

\newcommand{\eps}{\epsilon}
\newcommand{\grad}{\nabla}
\newcommand{\lam}{\lambda}
\newcommand{\lap}{\triangle}

\newcommand{\ip}[2]{\ensuremath{\left<#1,#2\right>}}

%\renewcommand{\det}{\operatorname{det}}
\newcommand{\onull}{\operatorname{null}}
\newcommand{\rank}{\operatorname{rank}}
\newcommand{\range}{\operatorname{range}}

\newcommand{\prob}[1]{\bigskip\noindent\textbf{#1.}\quad }
\newcommand{\exer}[2]{\prob{Exercise #2 in Lecture #1}}

\newcommand{\pts}[1]{(\emph{#1 pts}) }
\newcommand{\epart}[1]{\medskip\noindent\textbf{(#1)}\quad }
\newcommand{\ppart}[1]{\,\textbf{(#1)}\quad }

\newcommand{\Julia}{\textsc{Julia}\xspace}
\newcommand{\Matlab}{\textsc{Matlab}\xspace}
\newcommand{\Octave}{\textsc{Octave}\xspace}
\newcommand{\Python}{\textsc{Python}\xspace}

\DefineVerbatimEnvironment{mVerb}{Verbatim}{numbersep=2mm,
frame=lines,framerule=0.1mm,framesep=2mm,xleftmargin=4mm,fontsize=\footnotesize}

\newcommand{\ema}{\emach}
\newcommand{\emach}{\eps_{\!_{\text{m}}}}

\title{POPDIP: \\ a POsitive-variables Primal-Dual Interior Point method}
\author{Ed Bueler}
\date{\today}

\begin{document}
\maketitle

%\abstract{This is not research, but it is a new algorithm for me.  It is a version of the primal dual interior point algorithm in \cite{GrivaNashSofer2009}.}
\begin{abstract}
The algorithm documented here is a version of the primal-dual interior point algorithm in \cite{GrivaNashSofer2009}; see section 16.7 and Algorithm 16.1.  The version here minimizes a smooth nonlinear function subject to the constraints that all the variables are nonnegative.  That is, it is a specialized algorithm for nonnegativity constraints; it is not suitable for general inequality constraints.

These short notes are not research!  This algorithm is simply a special case of a well-known algorithm.  Furthermore ``POPDIP'' is just a name I made up; it is not in common use!  However, this class of algorithms is new to me so I am documenting it fully.
\end{abstract}

\thispagestyle{empty}

\bigskip
\subsection*{Introduction and algorithm design}

Consider a nonlinear optimization problem with nonnegativity (informally: positivity) constraints on the variables:
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{minproblem}
\end{equation}
As usual, ``$x\ge 0$'' means that each entry of $x\in\RR^n$ is nonnegative.  The feasible set for \eqref{minproblem} is the convex and closed set $S = \{x\in \RR^n\,:\,x\ge 0\}$ with interior $S^\circ = \{x\in \RR^n\,:\,x > 0\}$.

Here $f:\RR^n \to\RR^n$ is a continuous and smooth function.  In fact this algorithm only assumes $f$ is defined and smooth on $S^\circ$, but in practice, so as to have a chance of good performance, $f$ should be well-behaved near the boundary of $S$.

One can start the derivation by considering a logarithmic barrier function.  Let $\mu>0$.  If $x\in S^\circ$ then the following function is well-defined and finite:
\begin{equation}
\beta_\mu(x) = f(x) - \mu \sum_{i=1}^n \ln x_i \label{barrierfunction}
\end{equation}
Let $\{e_1,\dots,e_n\}$ be the standard basis of $\RR^n$.  The first-order necessary condition for the unconstrained problem of minimizing $\beta_\mu$, namely $\grad \beta_\mu(x)=0$ for $x \in S^\circ$, is
\begin{equation}
\grad f(x) - \mu \sum_{i=1}^n \frac{1}{x_i} e_i = 0 \label{firstorderbarrier}
\end{equation}

Conditions \eqref{firstorderbarrier} can be reformulated by defining additional variables
    $$\lambda_i = \frac{\mu}{x_i}$$
so that $\lambda\in\RR^n$.  Note that $\lambda>0$ if and only if $x>0$ because $\lambda_i x_i = \mu > 0$.  Then \eqref{firstorderbarrier}, plus feasibility for $x$, is precisely equivalent to the following nonlinear system of equations and inequalities:
\begin{align}
x &\ge 0 \label{firstordersystem} \\
\lambda &\ge 0 \notag \\
\grad f(x) - \lambda &= 0 \notag \\
\lambda_i x_i &= \mu, \qquad i=1,\dots,n \notag
\end{align}

The feasible set for $x$ and for $\lambda$ is the same, namely $S \subset \RR^n$.  Because of the last condition in \eqref{firstordersystem}, both $x$ and $\lambda$ are positive and thus in the interior $S^\circ$.  By contrast, for the general primal-dual interior point Algorithm 16.1 \cite[section 16.7]{GrivaNashSofer2009}, the feasible set for the primal variable $x$ is different from the dual feasible set for $\lambda$.  For example, generally the dimension is different.

The third condition in \eqref{firstordersystem} can be written using a Lagrangian function for \eqref{minproblem}, namely
\begin{equation}
\mathcal{L}(x,\lambda) = f(x) - \sum_{i=1}^n \lambda_i x_i,  \label{Lagrangian}
\end{equation}
in which case it states that $\grad_x \mathcal{L}(x,\lambda)=0$.  However, system \eqref{firstordersystem} describes a solution which is different from the KKT conditions for \eqref{minproblem}.  (See Lemma 14.8 and Theorem 14.18 in \cite{GrivaNashSofer2009}.)  Those KKT conditions are the same as system \eqref{firstordersystem} but with the last equation replaced by
\begin{equation}
\lambda_i x_i = 0, \qquad i=1,\dots,n  \label{complementaryslackness}
\end{equation}
That is, complementary slackness applies in the KKT conditions.  System \eqref{firstordersystem} modifies the KKT conditions by connecting the variables through equality with a positive constant ($\lambda_i x_i = \mu$).

Also, the stationary-point conditions for Lagrangian \eqref{Lagrangian}, namely $\grad_x\mathcal{L}(x,\lambda)=0$ and $\grad_\lambda\mathcal{L}(x,\lambda)=0$, do not generally apply because we have nonnegativity constraints on $x$ and \emph{not} equality constraints (which would make the problem trivial).  Of course $x_i=0$ holds when the $i$th constraint is active, but the algorithm here will not keep track of the active set.

Algorithm 16.1 \cite{GrivaNashSofer2009} applies to \eqref{minproblem}, and the POPDIP algorithm proposed below is the simplification which uses the fact that $g_i(x)=x_i$.  All such primal-dual interior point algorithms compute approximate solutions to systems like \eqref{firstordersystem} for a sequence $\{\mu_k\}$ going to zero.  In the limit where $\mu=0$, which is never achieved because the algorithm is terminated after a finite number of steps, the solution will solve \eqref{complementaryslackness}.

Each step of the algorithm is a Newton step for the equalities in \eqref{firstordersystem}, namely
\begin{align}
\grad f(x) - \lambda &= 0 \label{equalitysystem} \\
\lambda_i x_i &= \mu_k, \qquad i=1,\dots,n. \notag
\end{align}
The Newton method updates both $x$ and $\lambda$ using the linearization of these equations.  Because of the second equation, these equations are always nonlinear.  Note that if $f$ is quadratic then the first equation is linear.

To describe the Newton step let $x=x_k+\Delta x$ and $\lambda=\lambda_k+\Delta\lambda$.  We assume that the current iterate $(x_k,\lambda_k)$ does not solve \eqref{equalitysystem}.  The unknowns in the Newton step for the search direction $p=(\Delta x,\Delta \lambda)$.  Substituting into \eqref{equalitysystem} and expanding to first order gives
\begin{align}
\grad f(x_k) + \grad^2 f(x_k) \Delta x - \lambda_k - \Delta \lambda &= 0 \label{prenewtonstep} \\
(\lambda_k)_i (x_k)_i + (x_k)_i (\Delta\lambda)_i + (\lambda_k)_i (\Delta x)_i &= \mu_k, \qquad i=1,\dots,n \notag
\end{align}
Rearranging as a linear block system for the search direction, and suppressing the current-iterate subscript, we get the Newton step equations
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
\Lambda & X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
-\Lambda x + \mu_k e
\end{bmatrix}
 \label{newtonstep}
\end{equation}
Here $I$ is the $n\times n$ identity matrix and the other notation is as follows:
    $$\Lambda = \begin{bmatrix} \lambda_1 & & \\ & \ddots & \\ & & \lambda_n \end{bmatrix}, \qquad X = \begin{bmatrix} x_1 & & \\ & \ddots & \\ & & x_n \end{bmatrix}, \qquad e = \begin{bmatrix} 1 \\ \vdots \\ 1 \end{bmatrix}.$$

Given a solution of \eqref{newtonstep} the update formulas are
\begin{align*}
x_{k+1} &= x_k + \alpha_P \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha_D \Delta \lambda
\end{align*}
The maximum step sizes $\alpha_P,\alpha_D$ for the primal and dual variables are determined by separate ratio tests to achieve (strict) positivity of $x_{k+1}$ and $\lambda_{k+1}$, respectively.  Because this is a Newton search one uses $\alpha_P=\alpha_D=1$ for the largest allowed step.  Note we are not truly using $p=(\Delta x,\Delta \lambda) \in \RR^{2n}$ as a search direction because of the separate searches for the primal and dual variables.

The optimality test is the same as in Algorithm 16.1 \cite{GrivaNashSofer2009}.  It uses the merit function
    $$\nu(x,\lambda) = \max\{\|\grad f(x)-\lambda\|,\|\Lambda x\|\}$$
where $\|\cdot\|$ denotes the usual $L^2$ norm on $\RR^n$.  Note that once $\mu_k\to 0$ we have $\nu(x_*,\lambda_*) = 0$ for the exact optimum, but when $\mu_k \ne 0$ then the exact solution of \eqref{equalitysystem} does not make $\nu(x,\lambda)$ zero.  In fact $\nu(x_*,\lambda_*) = \sqrt{n}\, \mu_k$ for the exact solution of \eqref{equalitysystem}; if the merit function value $\nu(x_k,\lambda_k)$ is close to $\sqrt{n}\, \mu_k$ then we should decrease $\mu_k$ more rapidly.


\subsection*{Algorithm}

We can now present a pseudocode for our algorithm.

\bigskip
\noindent \textsc{Algorithm POPDIP.}
\begin{quote}
\begin{itemize}
\item[\emph{inputs}]  primal initial values $x_0$ such that $x_0 > 0$
\item[]  smooth function $f$ returning $f(x)$, $\grad f(x)$, and $\grad^2 f(x)$
\item[\emph{parameters}]  $\text{\texttt{tol}}>0$ [default $\text{\texttt{tol}}=10^{-4}$]
\item[]  $\mu_0>0$ [default $\mu_0=1$]
\item[]  $\theta>0$ [default $\theta=0.2$]
\item[]  $\kappa>0$ [default $\kappa=0.9$]
\item[\emph{output}]  an estimate $(x_k,\lambda_k)$ of the solution
\item  determine initial dual variables: $(\lambda_0)_i = \mu_0 / (x_0)_i$
\item  for $k=0,1,2,\dots$
    \renewcommand{\labelenumi}{(\roman{enumi})}
    \begin{enumerate}
    \item optimality test: if $\nu(x_k,\lambda_k)<\text{\texttt{tol}}$ then stop
    \item compute Newton step by solving this system for $(\Delta x,\Delta \lambda)$:
    $$\begin{bmatrix}
\grad^2 f(x_k) & - I \\
\Lambda_k & X_k
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x_k) + \lambda_k \\
-\Lambda_k x_k + \mu_k e
\end{bmatrix}$$
    \item ratio test for step sizes to keep $x_{k+1},\lambda_{k+1}$ positive:
\begin{align*}
\alpha_P &= \min_{1\le i\le n} \left\{1, \,-\kappa \frac{(x_k)_i}{(\Delta x)_i} \,:\, (\Delta x)_i < 0\right\} \\
\alpha_D &= \min_{1\le i\le n} \left\{1, \,-\kappa \frac{(\lambda_k)_i}{(\Delta \lambda)_i} \,:\, (\Delta \lambda)_i < 0\right\}
\end{align*}
    \item the update:
\begin{align*}
x_{k+1} &= x_k + \alpha_P \Delta x \\
\lambda_{k+1} &= \lambda_k + \alpha_D \Delta \lambda
\end{align*}
    \item the barrier parameter update:
        $$\mu_{k+1} = \theta \mu_k$$
    \end{enumerate}
\end{itemize}
\end{quote}

This algorithm is implemented by a \Matlab code with signature
\begin{center}
\texttt{function [xk,lamk,xklist,lamklist] = popdip(x0,f,tol,mu0,theta,kappa)}
\end{center}
Only inputs \texttt{x0,lam0,f} are required.  If outputs \texttt{xklist,lamklist} are not requested then they are not computed.  The parameters have the default values listed above.  Download at
\begin{center}
    \href{http://bueler.github.io/M661F18/matlab/popdip.m}{\texttt{bueler.github.io/M661F18/matlab/popdip.m}}
\end{center}

We may consider three possible areas for improvements of Algorithm 16.1.  First, in Algorithm 16.1 the computation of the Newton search direction is followed by separate line searches in $x$ and in $\lambda$.  These line searches only to maintain the nonnegativity requirements (generally: $g_i(x)\ge 0$ and $\lambda_i\ge 0$), and they do not seek sufficient decrease of $f(x)$ in particular, so they are just ratio tests.  Also, the same parameter $\kappa$ is used in both instances of the ratio test, and this could change.  Finally, equation \eqref{newtonstep} can be symmetrized by multiplying the second half of the equations by $-\Lambda^{-1}$:
\begin{equation}
\begin{bmatrix}
\grad^2 f(x) & - I \\
-I & - \Lambda^{-1} X
\end{bmatrix}
\begin{bmatrix}
\Delta x \\
\Delta \lambda
\end{bmatrix}
=
\begin{bmatrix}
-\grad f(x) + \lambda \\
x - \mu^{(k)} \Lambda^{-1} e
\end{bmatrix}
 \label{symmnewtonstep}
\end{equation}

These facts suggests four possible changes of Algorithm 16.1:
\begin{enumerate}
\item Back-tracking is not needed to maintain feasibility of the primal variables because of the linearity of the constraint functions in problem \eqref{minproblem}, namely $g_i(x)=x_i$.  A ratio test on $x$ suffices to keep $x$ feasible.
\item Back-tracking line search is appropriate as a globalization even for unconstrained optimization.  Thus there must be cases where it is appropriate for problem \eqref{minproblem} as well.  Compare the modified back-tracking line searches in \cite{BensonMunson2006}.
\item One could use separate parameters $\kappa_P,\kappa_D$ in the ratio tests.
\item One can replace linear system \eqref{newtonstep} with a symmetrized version, system \eqref{symmnewtonstep}.
\end{enumerate}
In POPDIP we have already implemented change 1.  Changes 2, 3, and 4 may generate further improvements, but that would require testing which we have not done.


\subsection*{Testing}

FIXME we start with a 2D easy test
\begin{equation}
\begin{matrix}
\text{minimize} \qquad & f(x) = \frac{1}{2} (x_1-1)^2 + \frac{1}{2} (x_2+1)^2 \\
\text{subject to} \qquad & x \ge 0
\end{matrix} \label{testoneproblem}
\end{equation}
For this problem the unconstrained minimum is the infeasible point $\hat x =(1,-1)^\top$.  A sketch shows the exact solution is $x_*=(1,0)^\top$.  We propose to use the default parameters and start with the feasible point $x_0=(2,2)^\top$.  Note the initial dual variables are then determined using $\mu_0=1$: $\lambda_0=(1/2,1/2)^\top$.


\subsection*{Application to example problem (\texttt{glacier}).}

FIXME a primal-dual interior point method for a glacier problem appears in \cite{Calvoetal2003}


\bibliography{doc}
\bibliographystyle{siam}

\end{document}

